{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMwCxVrVuKcM"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5T_UJwZuKcN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0I3IjWNuKcO"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X5_G-gBuKcO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXIsNE9WuKcO",
    "outputId": "32a614d8-b8e4-4483-92ac-03d5a3ff7cbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3   B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "5   B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                    \n",
       "1                      1                       1      5  1303862400   \n",
       "2                      0                       0      1  1346976000   \n",
       "3                      1                       1      4  1219017600   \n",
       "4                      3                       3      2  1307923200   \n",
       "5                      0                       0      5  1350777600   \n",
       "\n",
       "                  Summary                                               Text  \n",
       "Id                                                                            \n",
       "1   Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "2       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "3   \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "4          Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "5             Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbONTaXvuKcP"
   },
   "outputs": [],
   "source": [
    "# Retain only the columns to be used for training\n",
    "df[\"review\"] = df[\"Score\"].apply(lambda x: 0 if x<4 else 1)\n",
    "df = df[[\"Text\",\"review\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SAUb9PZuKcP"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buGwXYovuKcP"
   },
   "source": [
    "We will be filtering numbers using regex and filter any html tag with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSGRp6zyuKcQ"
   },
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    #text = BeautifulSoup(text).text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLCHcGUuuKcQ",
    "outputId": "dabfd6dc-d1be-4e9c-90d3-9f88969c5d91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>These stars are small, so you can give  -  of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568454</th>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  review\n",
       "Id                                                               \n",
       "1       I have bought several of the Vitality canned d...       1\n",
       "2       Product arrived labeled as Jumbo Salted Peanut...       0\n",
       "3       This is a confection that has been around a fe...       1\n",
       "4       If you are looking for the secret ingredient i...       0\n",
       "5       Great taffy at a great price.  There was a wid...       1\n",
       "...                                                   ...     ...\n",
       "568450  Great for sesame chicken..this is a good if no...       1\n",
       "568451  I'm disappointed with the flavor. The chocolat...       0\n",
       "568452  These stars are small, so you can give  -  of ...       1\n",
       "568453  These are the BEST treats for training and rew...       1\n",
       "568454  I am very satisfied ,product is as advertised,...       1\n",
       "\n",
       "[568454 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Text\"] = df[\"Text\"].apply(lambda x: process(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-2CFMEtuKcQ"
   },
   "source": [
    "### Balancing Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sb0KVJY8uKcQ"
   },
   "source": [
    "The dataset has almost 4 times the positive reviews compared to negative reviews. To counter this we can sample only a part of the positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIPDv0siuKcR",
    "outputId": "b9b87d46-b665-485b-f0ca-2ff2671eccdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    443777\n",
       "0    124677\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"].value_counts() # 1 for positive and 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Kbq5ShTuKcR"
   },
   "outputs": [],
   "source": [
    "positive_reviews = df[df.review == 1]\n",
    "negative_reviews = df[df.review == 0]\n",
    "\n",
    "positive_reviews = positive_reviews.sample(n=len(negative_reviews)) # sample positive examples whose number is equal to the negative examples\n",
    "\n",
    "df = positive_reviews.append(negative_reviews).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drUDRn8DuKcR",
    "outputId": "2a605dd8-ff87-44f6-9b4a-30f6226acebd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My wife is picky about her coffee. I myself ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cannot tell it from the syrup you get at Crack...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quaker Oatmeal Squares with a Hint of Brown Su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coffee was killing my stomach so I went in sea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy does this seasoning mix bring back memorie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249349</th>\n",
       "      <td>I just bought this soup today at my local groc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249350</th>\n",
       "      <td>This soup is mostly broth. Although it has a k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249351</th>\n",
       "      <td>It is mostly broth, with the advertised  /  cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249352</th>\n",
       "      <td>I had ordered some of these a few months back ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249353</th>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  review\n",
       "0       My wife is picky about her coffee. I myself ca...       1\n",
       "1       Cannot tell it from the syrup you get at Crack...       1\n",
       "2       Quaker Oatmeal Squares with a Hint of Brown Su...       1\n",
       "3       Coffee was killing my stomach so I went in sea...       1\n",
       "4       Boy does this seasoning mix bring back memorie...       1\n",
       "...                                                   ...     ...\n",
       "249349  I just bought this soup today at my local groc...       0\n",
       "249350  This soup is mostly broth. Although it has a k...       0\n",
       "249351  It is mostly broth, with the advertised  /  cu...       0\n",
       "249352  I had ordered some of these a few months back ...       0\n",
       "249353  I'm disappointed with the flavor. The chocolat...       0\n",
       "\n",
       "[249354 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# The data is not shuffled right now, but it can be shuffled once we call the train test split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26u5dRf-uKcR"
   },
   "outputs": [],
   "source": [
    "sentences = df[\"Text\"].values\n",
    "labels = df[\"review\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCjOO4F2uKcS"
   },
   "outputs": [],
   "source": [
    "# Define training and testing sets\n",
    "train_sentences,test_sentences,train_labels,test_labels = train_test_split(sentences,labels,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdF9CDiPuKcS"
   },
   "outputs": [],
   "source": [
    "del positive_reviews,negative_reviews,sentences,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NR0L8mt_uKcS"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axzSFSDquKcS"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64 # dimension of the embedding layer\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "vocab_size = 10000\n",
    "max_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrS2pgRFuKcS"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token=oov_tok) #Define tokenizer\n",
    "tokenizer.fit_on_texts(train_sentences) # Assign tokens based on words on training set\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences) # Create sequences based on tokens for the training set\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type) # pad/truncate zeros at the end for a length of 'max_length' \n",
    "\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences) # similar preprocessing for test set\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZJ3pc54uKcT"
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_a0PUD7uKcT",
    "outputId": "2a3d7b3c-184e-48bf-981e-5e90fe509a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 400, 64)           640000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 666,017\n",
      "Trainable params: 666,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(8,activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hVekLzUuKcT",
    "outputId": "15a55f48-f0b8-4a7a-d285-418c6be08bc7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1559/1559 [==============================] - 63s 40ms/step - loss: 0.4305 - accuracy: 0.8228 - val_loss: 0.3234 - val_accuracy: 0.8658\n",
      "Epoch 2/10\n",
      "1559/1559 [==============================] - 62s 40ms/step - loss: 0.3269 - accuracy: 0.8801 - val_loss: 0.2719 - val_accuracy: 0.8911\n",
      "Epoch 3/10\n",
      "1559/1559 [==============================] - 62s 40ms/step - loss: 0.2821 - accuracy: 0.9008 - val_loss: 0.2566 - val_accuracy: 0.8991\n",
      "Epoch 4/10\n",
      "1559/1559 [==============================] - 62s 40ms/step - loss: 0.2521 - accuracy: 0.9116 - val_loss: 0.2566 - val_accuracy: 0.9008\n",
      "Epoch 5/10\n",
      "1559/1559 [==============================] - 63s 40ms/step - loss: 0.2299 - accuracy: 0.9203 - val_loss: 0.2596 - val_accuracy: 0.9066\n",
      "Epoch 6/10\n",
      "1559/1559 [==============================] - 62s 40ms/step - loss: 0.2102 - accuracy: 0.9270 - val_loss: 0.2590 - val_accuracy: 0.9077\n",
      "Epoch 7/10\n",
      "1559/1559 [==============================] - 63s 40ms/step - loss: 0.1937 - accuracy: 0.9326 - val_loss: 0.2594 - val_accuracy: 0.9075\n",
      "Epoch 8/10\n",
      "1559/1559 [==============================] - 63s 40ms/step - loss: 0.1853 - accuracy: 0.9356 - val_loss: 0.2850 - val_accuracy: 0.9088\n",
      "Epoch 9/10\n",
      "1559/1559 [==============================] - 63s 40ms/step - loss: 0.1806 - accuracy: 0.9386 - val_loss: 0.2887 - val_accuracy: 0.9099\n",
      "Epoch 10/10\n",
      "1559/1559 [==============================] - 62s 40ms/step - loss: 0.1698 - accuracy: 0.9419 - val_loss: 0.3368 - val_accuracy: 0.9107\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_padded, train_labels, epochs=10, validation_data=(test_padded, test_labels),batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9T3N_6puKcT"
   },
   "source": [
    "# Get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g_IEYshhuKcU"
   },
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYog1Se_uKcU",
    "outputId": "e0a99f09-a89b-4585-94bb-ac77fb4055ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64)\n"
     ]
    }
   ],
   "source": [
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S78eLhgUuKcU"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "    word = reverse_word_index[word_num]\n",
    "    embeddings = weights[word_num]\n",
    "    out_m.write(word + \"\\n\")\n",
    "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gHq2aBLuKcU"
   },
   "source": [
    "# Predict using custom string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"Weights/LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKayP0NLuKcU"
   },
   "outputs": [],
   "source": [
    "test_string = \"this was the best food I had\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZdC7utZuKcU"
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(model,custom_text):\n",
    "    custom_sequence = tokenizer.texts_to_sequences(np.array([custom_text]))\n",
    "    custom_padded = pad_sequences(custom_sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "    if float(model.predict(custom_padded))>0.5:\n",
    "        print(\"The review has a positive sentiment :)\")\n",
    "    else:\n",
    "        print(\"The review has a negative sentiment :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8J6GK_xquKcV",
    "outputId": "0fac2ed1-8d6a-4de9-cb5d-7f28e60d2910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review has a positive sentiment :)\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment(model,test_string)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
